---
phase: 12-failure-learnings
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - bin/lib/learnings.sh
autonomous: true

must_haves:
  truths:
    - "When exit_code != 0, failure reason can be extracted from Claude's JSON output"
    - "Failure context has structured fields: task ID, timestamp, error, attempted, files, context"
    - "Failures are stored under ## Failure Context section in AGENTS.md"
    - "Phase-scoped subsections (### Phase N:) organize failures by phase"
    - "100-failure cap is enforced per phase, oldest dropped first"
  artifacts:
    - path: "bin/lib/learnings.sh"
      provides: "Failure extraction and storage functions"
      exports: ["ensure_failure_section", "extract_failure_reason", "append_failure_learning", "enforce_failure_cap", "clear_phase_failures"]
  key_links:
    - from: "extract_failure_reason"
      to: "jq JSON parsing"
      via: "parse .result and .error fields"
      pattern: "jq.*result.*error"
    - from: "append_failure_learning"
      to: "AGENTS.md Failure Context section"
      via: "awk section manipulation"
      pattern: "awk.*Failure Context"
---

<objective>
Add failure extraction and storage functions to learnings.sh

Purpose: Enable structured failure capture from Claude's JSON output so retries can learn from previous mistakes. This extends the existing learnings.sh infrastructure with failure-specific functions.

Output: Extended learnings.sh with ensure_failure_section, extract_failure_reason, append_failure_learning, enforce_failure_cap, and clear_phase_failures functions.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-failure-learnings/12-CONTEXT.md
@.planning/phases/12-failure-learnings/12-RESEARCH.md
@bin/lib/learnings.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add ensure_failure_section and extract_failure_reason functions</name>
  <files>bin/lib/learnings.sh</files>
  <action>
Add two new functions to learnings.sh after the existing Learning Storage Functions section:

**ensure_failure_section():**
- Check if `## Failure Context` section exists in AGENTS.md
- If not, append it after existing sections with intro text: "Failure learnings from current phase - cleared on phase completion."
- Return 0 always (creates file via init_agents_file if needed)

**extract_failure_reason(output_file):**
- Takes Claude's JSON output file path as argument
- Use jq to extract `.result` field first, then look for `FAILURE_REASON:` marker pattern
- If no structured marker, extract `.error` field as fallback
- If no jq, fall back to grep patterns for common error strings
- Truncate at 500 chars, preserving complete words
- Return extracted reason to stdout, or "Task failed (no specific error message captured)" as default
- Return 0 always (extraction is best-effort)

Follow existing patterns in learnings.sh (jq with grep fallback, color codes via LEARN_* variables, stderr for errors).
  </action>
  <verify>
Run these test commands:
```bash
source bin/lib/learnings.sh
# Test ensure_failure_section
ensure_failure_section
grep -q "## Failure Context" .planning/AGENTS.md && echo "PASS: Section exists"

# Test extract_failure_reason with mock JSON
echo '{"result": "FAILURE_REASON: npm test failed due to missing jest config", "error": null}' > /tmp/test_output.json
reason=$(extract_failure_reason /tmp/test_output.json)
echo "$reason" | grep -q "npm test failed" && echo "PASS: Extracted from result"

# Test fallback extraction
echo '{"error": "Command failed with exit code 1"}' > /tmp/test_error.json
reason=$(extract_failure_reason /tmp/test_error.json)
echo "$reason" | grep -q "exit code 1" && echo "PASS: Extracted from error field"

rm /tmp/test_output.json /tmp/test_error.json
```
  </verify>
  <done>ensure_failure_section creates the Failure Context section, extract_failure_reason parses Claude JSON for failure details with jq primary and grep fallback</done>
</task>

<task type="auto">
  <name>Task 2: Add append_failure_learning and enforce_failure_cap functions</name>
  <files>bin/lib/learnings.sh</files>
  <action>
Add two more functions to learnings.sh after the extraction functions:

**append_failure_learning(task_id, error_msg, attempted, files, context):**
- Extract phase number from task_id (e.g., "12-01" -> 12)
- Generate timestamp: `date '+%Y-%m-%d %H:%M:%S'`
- Format entry as multi-line markdown:
  ```
  - [{task_id} | {timestamp}] **Error:** {error_msg}
    **Attempted:** {attempted}
    **Files:** {files}
    **Context:** {context}
  ```
- Ensure failure section exists via ensure_failure_section
- Check cap via enforce_failure_cap before appending
- Use awk to insert under `### Phase {N}:` subsection of `## Failure Context`
- Create phase subsection if it doesn't exist (similar to append_learning pattern)
- Escape special sed/awk characters in error messages (/, \, &, ')
- Use atomic write pattern (mktemp + mv)

**enforce_failure_cap(phase_num):**
- Count failures for this phase: grep for lines starting with `- [{phase_num}-`
- If count >= 100, drop the oldest failure (first match for this phase)
- Use awk to skip first matching line
- Atomic write pattern

Both functions return 0 on success, 1 on invalid args.
  </action>
  <verify>
Run these test commands:
```bash
source bin/lib/learnings.sh
# Test append_failure_learning
append_failure_learning "12-01" "npm test failed" "Ran test suite to verify implementation" "bin/lib/learnings.sh" "Jest config missing in package.json"
grep -q "12-01.*npm test failed" .planning/AGENTS.md && echo "PASS: Failure appended"
grep -q "Attempted:.*Ran test suite" .planning/AGENTS.md && echo "PASS: Attempted field present"

# Test enforce_failure_cap doesn't break things
enforce_failure_cap 12
echo "PASS: Cap enforcement ran without error"

# Check structure
grep -q "### Phase 12:" .planning/AGENTS.md && echo "PASS: Phase subsection created"
```
  </verify>
  <done>append_failure_learning stores structured failures with all fields, enforce_failure_cap drops oldest when at 100 per phase</done>
</task>

<task type="auto">
  <name>Task 3: Add clear_phase_failures function</name>
  <files>bin/lib/learnings.sh</files>
  <action>
Add clear_phase_failures function for phase completion cleanup:

**clear_phase_failures(phase_num):**
- Remove leading zeros from phase_num: `phase_num=$((10#$phase_num))`
- If AGENTS.md doesn't exist, return 0 (nothing to clear)
- Use awk to remove the entire `### Phase {N}:` subsection from within `## Failure Context`
- The awk pattern should:
  1. Track when inside `## Failure Context` section
  2. Track when inside `### Phase {N}:` subsection
  3. Skip all lines until next `### Phase` or `## ` header
  4. Preserve everything else
- Atomic write pattern (mktemp + mv)
- Return 0 always

This function will be called by ralph.sh when a phase boundary is crossed (current task succeeds and next task is in a different phase).
  </action>
  <verify>
Run these test commands:
```bash
source bin/lib/learnings.sh
# Add a test failure first
append_failure_learning "12-02" "Test error" "Testing" "test.sh" "Test context"
grep -q "### Phase 12:" .planning/AGENTS.md && echo "PASS: Phase 12 failures exist"

# Clear phase 12 failures
clear_phase_failures 12
! grep -q "### Phase 12:" .planning/AGENTS.md && echo "PASS: Phase 12 failures cleared"

# Verify other sections still exist
grep -q "## Error Fixes" .planning/AGENTS.md && echo "PASS: Other sections preserved"
grep -q "## Failure Context" .planning/AGENTS.md && echo "PASS: Failure Context section preserved (empty)"
```
  </verify>
  <done>clear_phase_failures removes all failure entries for a specific phase while preserving other sections and the Failure Context header</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Verify all functions exist:
```bash
source bin/lib/learnings.sh
type ensure_failure_section &>/dev/null && echo "ensure_failure_section: OK"
type extract_failure_reason &>/dev/null && echo "extract_failure_reason: OK"
type append_failure_learning &>/dev/null && echo "append_failure_learning: OK"
type enforce_failure_cap &>/dev/null && echo "enforce_failure_cap: OK"
type clear_phase_failures &>/dev/null && echo "clear_phase_failures: OK"
```

2. Verify AGENTS.md has Failure Context section:
```bash
grep -q "## Failure Context" .planning/AGENTS.md && echo "Section structure: OK"
```

3. End-to-end test:
```bash
# Store a failure
append_failure_learning "12-test" "Integration test error" "Ran integration" "test.sh" "Expected 200, got 500"
# Verify it's there
grep -q "12-test.*Integration test error" .planning/AGENTS.md && echo "Storage: OK"
# Clear it
clear_phase_failures 12
# Verify it's gone
! grep -q "12-test" .planning/AGENTS.md && echo "Cleanup: OK"
```
</verification>

<success_criteria>
- learnings.sh contains 5 new functions: ensure_failure_section, extract_failure_reason, append_failure_learning, enforce_failure_cap, clear_phase_failures
- Functions follow existing learnings.sh patterns (atomic writes, color codes, jq with fallback)
- Failure entries have structured format with task ID, timestamp, error, attempted, files, context
- Phase subsections organize failures under ## Failure Context
- 100-failure cap per phase is enforced
- Phase cleanup removes all failures for that phase
- All verification commands pass
</success_criteria>

<output>
After completion, create `.planning/phases/12-failure-learnings/12-01-SUMMARY.md`
</output>
